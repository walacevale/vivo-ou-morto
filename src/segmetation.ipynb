{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os \n",
    "import glob\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastas_img = ['train' , 'train_mask']\n",
    "caminho_base = os.path.abspath('..')\n",
    "\n",
    "def caminho_image(numero_pasta, formato):\n",
    "    caminho_pastas_imgs = caminho_base + '/image/' + str(pastas_img[numero_pasta]) + '/'\n",
    "    caminho_imgs = glob.glob(caminho_pastas_imgs + '*.' + str(formato))\n",
    "    return caminho_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 1024  #padronizar o tamanho das imagens \n",
    "train = [] #colocar as imagens em forma de matriz\n",
    "mask  = []\n",
    "caminho_train = caminho_image(0, 'png')\n",
    "caminho_mask  = caminho_image(1, 'tiff')\n",
    "\n",
    "for varrer in range(len(caminho_train)):\n",
    "    image = plt.imread(caminho_train[varrer])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB )\n",
    "    image_resize = cv2.resize(image, (SIZE,SIZE))\n",
    "    train.append(image_resize)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "for varrer in range(len(caminho_mask)):\n",
    "    image = plt.imread(caminho_mask[varrer])\n",
    "    image_resize = cv2.resize(image, (SIZE,SIZE))\n",
    "    mask.append(image_resize)\n",
    "\n",
    "train = np.array(train)\n",
    "mask = np.array(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train \n",
    "y_train = mask\n",
    "y_train = np.expand_dims(y_train, axis = 3)\n",
    "#importante analizar as dimensoes das imagens. X_train é uma matriz (10, 64,64,3) q significa q a mesma tem 10 imagens com largura 64x64 e tres canais de cores RGB\n",
    "#logo para relizar as operações é preciso q y_train tbm tenha esse shape, por isso é necessario realizar a expand_dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = Sequential()\n",
    "feature.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(SIZE,SIZE, 3), strides=1, padding='same', activation='relu'))\n",
    "feature.add(Conv2D(filters=64, padding='same' , kernel_size=(3, 3), strides=1, activation='relu'))\n",
    "feature.add(BatchNormalization())\n",
    "\n",
    "#tudo q fazer aqui tem q resutar no msm numero de linhas para X e Y\n",
    "\n",
    "X = feature.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, X.shape[3])\n",
    "Y = y_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = Y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Label'] > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(['Label'], axis=1)\n",
    "y_train = df['Label']\n",
    "#podemos entao agora treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "#model = RandomForestClassifier(n_estimators = 50, random_state = 42, n_jobs= -1)\n",
    "\n",
    "# Train the model on training data\n",
    "# Ravel Y to pass 1d array instead of column vector\n",
    "#model.fit(X_train, y_train) #For sklearn no one hot encoding\n",
    "\n",
    "\n",
    "#filename = 'RF_model.sav'\n",
    "#pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "#READ EXTERNAL IMAGE...\n",
    "test_img = cv2.imread('136.png', cv2.IMREAD_COLOR)       \n",
    "test_img = cv2.resize(test_img, (SIZE, SIZE))\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "\n",
    "#predict_image = np.expand_dims(X_train[8,:,:,:], axis=0)\n",
    "X_test_feature = feature.predict(test_img)\n",
    "X_test_feature = X_test_feature.reshape(-1, X_test_feature.shape[3])\n",
    "\n",
    "prediction = loaded_model.predict(X_test_feature)\n",
    "\n",
    "prediction_image = prediction.reshape(mask.shape[1:])\n",
    "plt.imshow(prediction_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asd')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90aae88cd518f1f84c313003e1d4a35209ea74282b66ddc2a0786c0e628b0413"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
